#!/bin/bash
# S.Chekanov (ANL)

source ./setup.sh

PWD=`pwd`

echo "Clean data.." 
rm -f ./data/train.data ./data/test.data ./data/valid.data 

# use real Delphes
#rfast007 - pileups <mu>=40
#rfast006 - pileups <mu>=120
#rfast008 - pileups <mu>=0 ATLAS default card
XDIR="../makedata/out_ann_rfast008"

# merge all files into one data file. It will be randomized, with input and output on one line..
echo "Create flattened randomized input.."
python2 merger_data_flattener.py /tmp/data.txt $XDIR/jet_pt_v0.d $XDIR/jet_pt_v2.d $XDIR/jet_pt_v3.d \
                                 $XDIR/jet_pt_v4.d $XDIR/jet_pt_v5.d $XDIR/jet_pt_v6.d \
                                 $XDIR/jet_pt_v7.d $XDIR/jet_pt_v8.d $XDIR/jet_pt_v9.d

echo "Make ./data/train.data ./data/test.data ./data/valid.data" 
python2 merger_get.py 1 4000001        /tmp/data.txt ./data/train.data
python2 merger_get.py 4000001 6000001  /tmp/data.txt ./data/test.data
python2 merger_get.py 6000001 8000001  /tmp/data.txt ./data/valid.data
rm -f /tmp/data.txt

# use fake data
#cd data
#ln -s ../../makedata/train1.data train.data; ln -s ../../makedata/data/test1.data  $PWD/data/test.data
#cd ..

#cd data
#cp ../merger_data.py .
#chmod 755 *
#python2 merger_data.py ./train.data $XDIR/jet_pt_v0.d $XDIR/jet_pt_v3.d $XDIR/jet_pt_v4.d 
#python2 merger_data.py ./test.data  $XDIR/jet_pt_v1.d $XDIR/jet_pt_v2.d 
#python2 merger_data.py ./valid.data $XDIR/jet_pt_v5.d $XDIR/jet_pt_v6.d 
# this is a fast checking..
#ln -s ../../makedata/out_ann_rfast007/jet_pt_v0.d train.data; 
#ln -s ../../makedata/out_ann_rfast007/jet_pt_v1.d test.data
#cd ..


# train NN using train1.data sample 
./ana train 

sleep 1

# validation and create prediction
./ana run
